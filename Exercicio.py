# -*- coding: utf-8 -*-
"""Avaliação Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10EpqAzA1CBeRo4Q3YIlOKYV98mNFRCSg
"""

# A atividade deverá ser realizada em um novo arquivo do Google Colab.
# Com o arquivo csv que você pesquisou, execute as seguintes atividades:

# https://www.kaggle.com/datasets/nelgiriyewithana/top-spotify-songs-2023?resource=download

# 1 - Inicie o ambiente Spark através da biblioteca pyspark e crie o objeto spark para manipulação dos dados.

# 2 – Altere o nome de pelo menos duas colunas de seu Data Frame.

# 3 – Converta o tipo de dados de alguma coluna de sua escolha: Pode ser uma conversão para float, int ou date.

# 4 – Realize 3 consultas através da função pyspark.sql. Pelo menos uma das consultas deve conter alguma função de agregação: count(), sum(), avg(), etc.
# Descreva qual o tipo de análise você fará no Data Frame e depois exiba o código em Python com o resultado da análise.

# 5 – Com alguma das consultas da atividade 3 crie um novo DataFrame e salve-o em formato .csv e em formato .orc.

# 1. Iniciando ambiente spark
!pip install pyspark
from pyspark.sql import SparkSession
from pyspark.sql import functions as f

# Criando o objeto spark
spark = SparkSession.builder.appName("Most Streamed Spotify Songs 2023").getOrCreate()

# 2. Alterando o nome de duas colunas do Data Frame.

# Importando arquivos para o spark
url = "/content/drive/MyDrive/Curso SENAI/Arquivo para Avaliação/Most Streamed Spotify Songs 2023/spotify-2023.csv/"

musicas = spark.read.options(header=True).csv(
    url,
    sep=",",
    inferSchema=True
)

musicas = musicas.withColumnsRenamed({
    "track_name":"Titulo_Faixa",
    "artist(s)_name":"Nome_Artista",
    "released_year": "Ano_Lancamento"})

# 3. Converta o tipo de dados de alguma coluna de sua escolha: Pode ser uma conversão para float, int ou date.

musicas = musicas.withColumn("bpm", musicas.bpm.cast("float"))

musicas.printSchema()

# 4 – Realize 3 consultas através da função pyspark.sql. Pelo menos uma das consultas deve conter alguma função de agregação: count(), sum(), avg(), etc.
# Descreva qual o tipo de análise você fará no Data Frame e depois exiba o código em Python com o resultado da análise.

# Criando os views do DataFrame:
musicas.createOrReplaceTempView("V_musicas")

# Usando a função spark.sql
consulta_tabelas = spark.sql( """
 SELECT * FROM V_musicas
"""
).show(3, False)

# Contando a quatidade de artistas
consulta_um = spark.sql( """
 SELECT COUNT(*) Nome_Artista FROM V_musicas
"""
).show()

# Média de batida por minuto (bpm)
consulta_dois = spark.sql( """
 SELECT AVG(bpm) AS media FROM V_musicas
"""
).show()

# Musica mais reproduzida
colsulta_tres = spark.sql( """
  SELECT MAX(Streams) AS Streams, Titulo_Faixa FROM V_musicas GROUP BY Titulo_Faixa
 """
).show(3, False)

# 5. Com alguma das consultas da atividade 3 crie um novo DataFrame e salve-o em formato .csv e em formato .orc.

# Criando novo data frame:
novoDf = spark.sql( """
    SELECT * FROM V_musicas
    """
)

# Salvando data frame em formato .orc:
url = "/content/drive/MyDrive/Curso SENAI/Arquivo para Avaliação/Most Streamed Spotify Songs 2023/Arquivo em orc"
novoDf.coalesce(1).write.orc(
    url,
    mode="overwrite"
)

# Salvando data frame em formato .orc:
url = "/content/drive/MyDrive/Curso SENAI/Arquivo para Avaliação/Most Streamed Spotify Songs 2023/Arquivo em csv"
novoDf.coalesce(1).write.csv(
    url,
    mode="overwrite"
)